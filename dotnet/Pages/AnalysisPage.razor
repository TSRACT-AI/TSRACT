@page "/analysis"
@implements IAsyncDisposable
@using PythonScripts
@using System.Text.RegularExpressions;
@inject LanguageModelService _languageModelService
@inject PromptLogService _promptLogService
@inject NodeProfileService _nodeProfileService
@inject ISnackbar _snackbar

<PageTitle>@_nodeProfileService.Profile.Name | Analysis</PageTitle>

<MudAppBar Color="Color.Transparent" Elevation="1">
    <MudStack Row="true">
        <MudSelect Label="Base Model" @bind-Value="_selectedModel" Dense="true" Style="min-width: 380px;" Disabled="_loading">
            <MudSelectItem Value="@("openlm-research/open_llama_7b")">openlm-research/open_llama_7b</MudSelectItem>
        </MudSelect>

        <MudSelect Label="LoRA" @bind-Value="_loraPath" Dense="true" Style="min-width: 380px;" Disabled="_loading">
            <MudSelectItem Value="@("")"></MudSelectItem>
            @foreach (LanguageModel model in _languageModels)
            {
                <MudSelectItem Value="@model.Path">@model.Path</MudSelectItem>
            }
        </MudSelect>

        @if (_modelLoaded)
        {
            <MudButton OnClick="ReloadModel" Color="Color.Primary" Variant="Variant.Filled" Class="my-2" Disabled="_loading">Reload Model</MudButton>
        }
        else
        {
            <MudButton OnClick="LoadModel" Color="Color.Primary" Variant="Variant.Filled" Class="my-2" Disabled="_loading">Load Model</MudButton>
        }
        
        <MudButton OnClick="LoadModel" Color="Color.Primary" Variant="Variant.Outlined" Class="my-2" Disabled="_loading">Re-Scan Model Cache</MudButton>
    </MudStack>
    
    <MudSpacer />
    
    @if (_downloadingModel == true)
    {
        <pre>
            @_downloadRepoScript.Stdout
            <br />@_downloadRepoScript.Stderr
        </pre>
    }
    else
    {
        <pre>
            @_nextTokenProbsScript.Stdout
            <br />@_nextTokenProbsScript.Stderr
        </pre>
    }
</MudAppBar>

@if (!_modelLoaded)
{
    return;
}

<MudGrid Class="mt-2">
    <MudItem sm="12" md="4">
        <MudPaper Class="pa-6" Elevation="2">
            <MudText Typo="Typo.h5" Class="my-0">Prompt</MudText>
            <MudTextField @bind-Value="_prompt" Variant="Variant.Outlined" Lines="9" Disabled="_loading" />
            <MudTextField @bind-Value="_generatedText" Variant="Variant.Outlined" Lines="9" Disabled="_loading" />
            <MudStack Row="true">
                <MudSpacer />
                <MudNumericField @bind-Value="_maxNewTokens" Label="Max. New Tokens" Min="1" Disabled="_loading" />
                <MudButton OnClick="GenerateText" Color="Color.Primary" Variant="Variant.Filled" Class="mt-2 object-right" Disabled="_loading">Generate</MudButton>
            </MudStack>
        </MudPaper>
    </MudItem>

    <MudItem sm="12" md="4">
        <MudPaper Class="pa-6" Elevation="2">
            <MudText Typo="Typo.h5" Class="my-0">First Token Probabilities</MudText>
            @if (!_loading && _nextTokenProbsArr.Length > 0)
            {
                <MudTable Items="_nextTokenProbsArr.Take(100)" Dense="true" Height="380px" FixedHeader="true">
                    <HeaderContent>
                        <MudTh>Token ID</MudTh>
                        <MudTh>Text</MudTh>
                        <MudTh>Probability</MudTh>
                    </HeaderContent>
                    <RowTemplate>
                        <MudTd><MudLink OnClick="_ => AddToken(context.Item1)" Color="Color.Primary" Size="Size.Small" Class="my-0">Add</MudLink></MudTd>
                        <MudTd><pre>@context.Item1</pre></MudTd>
                        <MudTd>@context.Item2.ToString("0.000000")</MudTd>
                    </RowTemplate>
                </MudTable>
            }
        </MudPaper>
    </MudItem>

    <MudItem sm="12" md="4">
        <MudPaper Class="pa-6" Elevation="2">
            <MudText Typo="Typo.h5" Class="my-0">Token Watch List</MudText>
            @if (!_loading && _tokenWatchListResult.Count() > 0)
            {
                <MudTable Items="_tokenWatchListResult" Dense="true" Height="380px" FixedHeader="true">
                    <HeaderContent>
                        <MudTh>Token ID</MudTh>
                        <MudTh>Text</MudTh>
                        <MudTh>Rank</MudTh>
                        <MudTh>Probability</MudTh>
                    </HeaderContent>
                    <RowTemplate>
                        <MudTd>@context.Item1</MudTd>
                        <MudTd><pre>@_vocab[context.Item1]</pre></MudTd>
                        <MudTd>@context.Item2</MudTd>
                        <MudTd>@context.Item3.ToString("0.000000")</MudTd>
                    </RowTemplate>
                </MudTable>
            }
            else
            {
                <MudTable Items="_tokenWatchList.OrderBy(x => x.Key)" Dense="true">
                    <HeaderContent>
                        <MudTh>Token ID</MudTh>
                        <MudTh>Text</MudTh>
                        <MudTh>&nbsp;</MudTh>
                    </HeaderContent>
                    <RowTemplate>
                        <MudTd>@context.Key</MudTd>
                        <MudTd><pre style="background-color: #eee;">@context.Value</pre></MudTd>
                        <MudTd><MudLink OnClick="_ => _tokenWatchList.Remove(context.Key)" Color="Color.Secondary">Remove</MudLink></MudTd>
                    </RowTemplate>
                </MudTable>
            }
        </MudPaper>
    </MudItem>

    <MudItem xs="3">
        <MudPaper Class="pa-8" Elevation="2">
            <MudText Typo="Typo.h6">Add Tokens to Watch List</MudText>
            <TokenPicker Vocabulary="_vocab"
                         SelectedTokens="_tokenWatchList"
                         OnTokenAdd="(tokenId) => _tokenWatchList.Add(tokenId, _vocab[tokenId])"
                         OnTokenRemove="(tokenId) => _tokenWatchList.Remove(tokenId)" />
        </MudPaper>
    </MudItem>
</MudGrid>

@code
{
    private bool _loading = true;
    private bool _modelLoaded = false;

    private List<LanguageModel> _languageModels = new();
    private string _selectedModel = "";
    private string _loraPath = "";
    private Dictionary<int, string> _vocab = new();

    private string _prompt = "2+2=";
    private int _maxNewTokens = 256;
    private string _generatedText = "";

    private List<(int, string)> _generatedTokens = new();

    private (string, double)[] _nextTokenProbsArr = Array.Empty<(string, double)>();
    private Dictionary<int, string> _tokenWatchList = new(); // (token, text)
    private List<(int, int, double)> _tokenWatchListResult = new(); // (token, rank, probability)
    private bool _downloadingModel = false;
    private DownloadHfRepo _downloadRepoScript = new();
    private NextTokenProbs _nextTokenProbsScript = new();

    protected override async Task OnInitializedAsync()
    {
        _languageModels = await _languageModelService.GetAll();
        _downloadRepoScript.OnOutput += OnScriptOutput;
        _nextTokenProbsScript.OnOutput += OnScriptOutput;
        _loading = false;
    }

    public async ValueTask DisposeAsync()
    {
        _downloadRepoScript.OnOutput -= OnScriptOutput;
        _nextTokenProbsScript.OnOutput -= OnScriptOutput;
        _nextTokenProbsScript.StopModel();
    }

    private async Task AddToken(string token)
    {
        _prompt += token;
        await GenerateText();
    }

    private async Task GenerateText()
    {
        _loading = true;
        InvokeAsync(StateHasChanged);

        PromptLogEntry logEntry = new PromptLogEntry() {  PromptText = _prompt };
        _generatedTokens.Clear();
        _generatedText = "";

        foreach (int token in await _nextTokenProbsScript.GenerateText(_prompt, _maxNewTokens))
        {
            _generatedTokens.Add((token, _vocab[token]));
            _generatedText += _vocab[token];
            logEntry.ResponseTokens.Add(token);
        }

        // Replace hex character codes with actual characters, primarily fixes newlines (<0x0a> -> \n)
        _generatedText = Regex.Replace(_generatedText, "<0x([A-Fa-f0-9]{2})>", m => ((char)Convert.ToInt32(m.Groups[1].Value, 16)).ToString());
        logEntry.ResponseText = _generatedText;

        _nextTokenProbsArr = new (string, double)[_vocab.Count];
        _tokenWatchListResult = new();
        int i = 0;
        foreach (var kvp in await _nextTokenProbsScript.GetNextTokenProbs(_prompt))
        {
            _nextTokenProbsArr[i] = (_vocab[kvp.Key], kvp.Value);
            // check token watchlist
            if (_tokenWatchList.ContainsKey(kvp.Key)) _tokenWatchListResult.Add((kvp.Key, i + 1, kvp.Value));
            i++;
        }


        logEntry.TokenWatchList = _tokenWatchListResult;

        await _promptLogService.Log(logEntry);

        _loading = false;
        _snackbar.Add($"Complete.", Severity.Success);
        InvokeAsync(StateHasChanged);
    }

    private async Task LoadModel()
    {
        _loading = true;
        InvokeAsync(StateHasChanged);
        _snackbar.Add($"Loading model {_selectedModel}...", Severity.Info);

        DumpTokenizer dumpScript = new();

        _vocab = await dumpScript.GetTokenizerVocabulary(_selectedModel, _nodeProfileService.BypassConda);
        await _nextTokenProbsScript.LoadModel(_selectedModel, _loraPath, _nodeProfileService.BypassConda);
        _modelLoaded = true;
        _loading = false;
        _snackbar.Add($"Loaded model {_selectedModel}.", Severity.Success);
    }

    private void OnScriptOutput(object? sender, EventArgs e)
    {
        InvokeAsync(StateHasChanged);
    }

    private async Task ReloadModel()
    {
        _nextTokenProbsScript.StopModel();
        _modelLoaded = false;
        await InvokeAsync(StateHasChanged);
        await LoadModel();
    }

    private async Task ReScanModels()
    {
        await _languageModelService.ScanHfCache();
        _languageModels = await _languageModelService.GetAll();
    }
}
